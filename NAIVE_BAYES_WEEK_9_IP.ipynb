{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NAIVE BAYES WEEK 9 IP",
      "provenance": [],
      "collapsed_sections": [
        "Mz4iqUZOs8eO",
        "ZmtpGWTDxGEZ",
        "gv9US9jWxiwy",
        "gPWYVIg6xoKJ",
        "XmSaRUtfAb4W",
        "Av5dsDRLzKSS",
        "1ijhcGhpzrkH",
        "y3bne9oy-NAT",
        "wttP3MSn-U0i",
        "W58Ki1eZE8Ks",
        "d3Et4zS15b6K",
        "NZnVC7Z4UbcJ",
        "rXxe5QXufg1s",
        "jn0fanGLEuxE",
        "iwKSbXyebPax",
        "-s5YmC77bWVq",
        "RKak17pQCbIh",
        "8hcT4MfSSWLk",
        "fKE30UppVn06",
        "-PGU7MdjC-6_"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Molly-Abisage/WK9_KNN-and-NAIVE-BAYES-CLASSIFIERS/blob/main/NAIVE_BAYES_WEEK_9_IP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gib73R8XX7Ga"
      },
      "source": [
        "##1. Defining the question"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IU3j1Vh0X_RN"
      },
      "source": [
        "### Specifying the research question"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TN0p96fby2a"
      },
      "source": [
        "*   We have been given a dataset containing details on emails with malicious and legitimate information, with the features describing what kind of content is in these emails, we are required to use the Naive Bayes Classifier to identify an email as spam or not spam.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89TJw4p8n9AW"
      },
      "source": [
        "###Defining the metrics for success"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7y-Sl1BLefSd"
      },
      "source": [
        "The metrics of this study is:\n",
        "\n",
        "*   Obtaining an accuracy score of at least 90% on the model\n",
        "*   Use of the most appropriate metrics to assess our models and explain why they are appropriate.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfOsOxa8oBFm"
      },
      "source": [
        "### Context"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zJ1oFtdpkBq"
      },
      "source": [
        "\n",
        "**Spam detection**\n",
        "\n",
        "Accurate spam detection is considered a difficult task due to several reasons including:\n",
        "*    **subjective nature of spam** - _for instance, a message containing several drug names might be a spam, but it might not be the case if the message is exchanged in a context of medical organizations_ \n",
        "\n",
        " \n",
        "This study will therefore make use of the Naive Bayes Classifier to detect if an email is spam or not.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5cf-NNRoIOO"
      },
      "source": [
        "###Record the experimental design"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PO_ccymYgvbY"
      },
      "source": [
        "The following steps will be followed for the study:\n",
        "\n",
        "1.   Importing libraries and loading data from a csv file\n",
        "1.   Checking the data\n",
        "1.   Conducting necessary data cleaning procedures\n",
        "1.   Performing Exploratory Data Analysis\n",
        "1.   Performing data pre-processing\n",
        "1.   Building the most suitable model for this study\n",
        "1.   Assessing/ Evaluating the model\n",
        "1.   Making a conclusion on the study\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxYhJXBgr7ZJ"
      },
      "source": [
        "###Data Relevance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXw-imJUr9yC"
      },
      "source": [
        "\n",
        "An assumption of Spam detection that its content differs from that of a legitimate email. \n",
        "\n",
        "Statically features of a typical spam email include:\n",
        "1.   char_freq_! \n",
        "1.   word_freq_remove \n",
        "1.   word_feq_credit \n",
        "1.   char_feq_\n",
        "1.   word_feq_hp \n",
        "1.   word_feq_edu \n",
        "1.   capital_run_length_longest \n",
        "1.   word_feq_free \n",
        "1.   capital_run_length_total \n",
        "1.   word_feq_george \n",
        "\n",
        "The dataset provided contains all these features hence we consider the data relevant for the study.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVgH2Ri0rPLP"
      },
      "source": [
        "##2. Reading the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuN4OdIOYA5Q"
      },
      "source": [
        "# importing libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nx6pxyV-BxxP"
      },
      "source": [
        "# loading datasets\n",
        "spam = pd.read_csv(\"/content/spambase_csv.csv\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oM0g8sOzrgGR"
      },
      "source": [
        "##3. Checking the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PttslVknrdL3"
      },
      "source": [
        "# previewing the top of the dataset\n",
        "spam.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xc2dsS6EDYef"
      },
      "source": [
        "# previewing the bottom of the dataset\n",
        "spam.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Q3OZ_-ADrun"
      },
      "source": [
        "# checking the size of the dataset\n",
        "spam.shape\n",
        "\n",
        "display(\"There are {} observations with {} features \".format(spam.shape[0], spam.shape[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajoYPgIMDgGR"
      },
      "source": [
        "# investigating the features\n",
        "spam.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nA5VHJQDDpgd"
      },
      "source": [
        "# checking data types\n",
        "spam.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpvxtAKqst5y"
      },
      "source": [
        "All the columns contained above are numerical features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mz4iqUZOs8eO"
      },
      "source": [
        "##4. External dataset validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRSs6DAH3gSl"
      },
      "source": [
        "spam.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spNKSsLxtDWz"
      },
      "source": [
        "According to https://help.campaignmonitor.com/\n",
        "Spam filters look at an email as a whole, with thresholds set for certain criteria. If a threshold is exceeded, the email gets marked as spam. Some things that can be caught by spam filters can include:\n",
        "\n",
        "*  An entire email composed of capital letters \n",
        "*  Frequent, random capitalization \n",
        "\n",
        "From the statistical properties above, we can see that the highest value of total number of capital letters in one email is 15, 841 (which is too high) has been categorized as spam hence we can conclude that this data is valid and can be used for this study.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmtpGWTDxGEZ"
      },
      "source": [
        "## Tidying the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gv9US9jWxiwy"
      },
      "source": [
        "###Completeness"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klq5ogJlxB2y"
      },
      "source": [
        "# checking for missing data\n",
        "spam.isnull().values.any()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lS6Rqpb6xfGg"
      },
      "source": [
        "The dataset is complete as we don't have any missing values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPWYVIg6xoKJ"
      },
      "source": [
        "###Consistency"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ou9dUOLGxdfD"
      },
      "source": [
        "print(spam[spam.duplicated()])\n",
        "\n",
        "# print(train_df[train_df.duplicated()])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lE5jBBhw_bIO"
      },
      "source": [
        "The duplicated object outputs 391 rows that seem to have duplicates. Most of the columns may have similar values but we can clearly see that the _capital_run_length_total_ column has a different value for each record hence we will retain this records as they are not really duplicates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmSaRUtfAb4W"
      },
      "source": [
        "###Uniformity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6DSg_pEyvIz"
      },
      "source": [
        "spam.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFwldOv6AhW8"
      },
      "source": [
        "All the column have appropriate data types"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Av5dsDRLzKSS"
      },
      "source": [
        "###Outliers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0EhbICLzNHa"
      },
      "source": [
        "# numerical_columns = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n",
        "\n",
        "fig, ax = plt.subplots(len(spam.columns), figsize = (18, 100))\n",
        "\n",
        "for i, col_val in enumerate(spam.columns):\n",
        "\n",
        "  sns.boxplot(y= spam[col_val], ax=ax[i])\n",
        "  ax[i].set_title('Box plot-{}'.format(col_val), fontsize=10)\n",
        "  ax[i].set_xlabel(col_val, fontsize=8)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5U2Yc841A2Hi"
      },
      "source": [
        "**Observations**\n",
        "\n",
        "Most of the columns seem to have most of the data points concentrated at zero. The columns also seem to have a few observations as outlier values. \n",
        "\n",
        "**Conclusion**\n",
        "\n",
        "As the outlier values are the one's that determine if an email will be classified as spam or not, we will retain them. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ijhcGhpzrkH"
      },
      "source": [
        "## Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTF-ujrbztQW"
      },
      "source": [
        "!pip install -U pandas-profiling"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcFCbNADzuJd"
      },
      "source": [
        "import pandas_profiling as pp\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from pandas_profiling import ProfileReport\n",
        "ProfileReport(spam, title = \"spam email report\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3bne9oy-NAT"
      },
      "source": [
        "##Univariate Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmIqcOmTL13g"
      },
      "source": [
        "# statistical summary\n",
        "spam.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wttP3MSn-U0i"
      },
      "source": [
        "###Distribution plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vLDRupq-QvB"
      },
      "source": [
        "# plotting distribution plots for all the above columns \n",
        "\n",
        "sns.set_style('darkgrid')\n",
        "fig, axes = plt.subplots(len(spam.columns), figsize = (18, 100))\n",
        "fig.suptitle('Distributions of all columns', y= 1.01, color = 'black', fontsize = 15)\n",
        "\n",
        "for ax, data, name in zip(axes.flatten(), spam, spam.columns):\n",
        "  sns.distplot(spam[name], ax = ax, kde = True, color = 'purple')\n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITg0VsPrCTMg"
      },
      "source": [
        "**Observations**\n",
        "\n",
        "All the independent variables have the mode at 0 and are positively skewed. The dependent variable is categorical."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W58Ki1eZE8Ks"
      },
      "source": [
        "###Target variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmFZLak_EwOW"
      },
      "source": [
        "# obtaining the count of the target variable\n",
        "\n",
        "spam[\"class\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpSxZA9GE2VW"
      },
      "source": [
        "We have a total of 2788 counts if class 0 (not spam) and 1813 (spam) hence we are dealing with an imbalanced class of more emails that were identified as no spam as compared to those identified as spam."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvszcMUZfeeb"
      },
      "source": [
        "# visualizing the target variable\n",
        "\n",
        "sns.catplot(y=\"class\", kind=\"count\", edgecolor=\".6\", data=spam);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0eo3d3fF9m3"
      },
      "source": [
        "The plot affirms the counts as had been stated above"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3Et4zS15b6K"
      },
      "source": [
        "##Bivariate Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPpDgW4gGOgS"
      },
      "source": [
        "We will use whiskerplots to see how the target variable relates to some numerical columns\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ib82e88GtjH"
      },
      "source": [
        "# the columns capital_run_length_average, capital_run_length_longest, capital_run_length_total deal with number of capital \n",
        "# letters in an email. Let's explore how class relate with this\n",
        "# plotting whisker plots\n",
        "capital_columns = ['capital_run_length_average', 'capital_run_length_longest', 'capital_run_length_total']\n",
        "\n",
        "fig, ax = plt.subplots(3, 1, figsize=(10, 12))\n",
        "\n",
        "for var, subplot in zip(capital_columns, ax.flatten()):\n",
        "    sns.boxplot(x='class', y=var, data=spam, ax=subplot)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-JaibbfIkbf"
      },
      "source": [
        "**Observations:**\n",
        "\n",
        "Spam emails have such high values of capital letters as compared to emails that are not spam. However, for the _capital_run_length_total_ column, the number of observations seem to be the same in both classes only that class 1 has more observations as outliers as compared to class 0. Most of the spam emails have observations concentrated around the zero mark with a few points as outliers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSp2-DW0KPSj"
      },
      "source": [
        "# let's see how the percentage of characters in an email relate to spam emails \n",
        "# \n",
        "character_columns = ['char_freq_%3B', 'char_freq_%28', 'char_freq_%5B', 'char_freq_%21', 'char_freq_%24', 'char_freq_%23']\n",
        "\n",
        "fig, ax = plt.subplots(3, 2, figsize=(10, 12))\n",
        "\n",
        "for var, subplot in zip(character_columns, ax.flatten()):\n",
        "    sns.boxplot(x='class', y=var, data=spam, ax=subplot)              \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yFHZdiAL-Mh"
      },
      "source": [
        "**Observations**:\n",
        "\n",
        "Depending on the type of character, an email can either be a spam or not a spam. Emails that are not spam have more of **char_freq_%3B, char_freq_%5B, 'char_freq_%21** characters while spam emails have more of **char_freq_%28, char_freq_%24, 'char_freq_%23** characters. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wl8iVR7ON0x"
      },
      "source": [
        "# # let's see how the type of words in an email relate to the email being spam or not\n",
        "\n",
        "\n",
        "word_columns = ['word_freq_make', 'word_freq_address', 'word_freq_all', 'word_freq_3d','word_freq_our', 'word_freq_over', \n",
        "       'word_freq_remove','word_freq_internet', 'word_freq_order', 'word_freq_mail','word_freq_receive', 'word_freq_will', \n",
        "       'word_freq_people', 'word_freq_report', 'word_freq_addresses', 'word_freq_free','word_freq_business', 'word_freq_email', \n",
        "       'word_freq_you', 'word_freq_credit', 'word_freq_your', 'word_freq_font', 'word_freq_000','word_freq_money', 'word_freq_hp', \n",
        "       'word_freq_hpl', 'word_freq_george','word_freq_650', 'word_freq_lab', 'word_freq_labs', 'word_freq_telnet','word_freq_857', \n",
        "       'word_freq_data', 'word_freq_415', 'word_freq_85','word_freq_technology', 'word_freq_1999', 'word_freq_parts','word_freq_pm', \n",
        "       'word_freq_direct', 'word_freq_cs', 'word_freq_meeting','word_freq_original', 'word_freq_project', 'word_freq_re',\n",
        "       'word_freq_edu', 'word_freq_table', 'word_freq_conference']\n",
        "\n",
        "fig, ax = plt.subplots(12, 4, figsize=(18, 40))\n",
        "\n",
        "for var, subplot in zip(word_columns, ax.flatten()):\n",
        "    sns.boxplot(x='class', y=var, data=spam, ax=subplot)              "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUSsvpDIQSMP"
      },
      "source": [
        "**Observations:**\n",
        "Words that are more frequent is spam emails as compared to emails that are not spam include: _3d, internet, remove, addresses, receive, credit, money, font, business, 000\n",
        "\n",
        "Words that are more frequent in emails that are not spam as compared to spam emails include: _re, edu, table, conference, cs, meeting, original, direct, project, 1999, parts, pm, 415, data, technology, lab, labs, hp, hpl, george, our, people, report, over, address, all, mail\n",
        "\n",
        "Some words are equally represented in both classes such as: make, order, will, your. Others are outliers in both kinds of emails."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZnVC7Z4UbcJ"
      },
      "source": [
        "###Feature Reduction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k87bfELD5lIT"
      },
      "source": [
        "# Data Reduction\n",
        "X = spam.drop('class', axis = 1)\n",
        "y = spam['class']    \n",
        "\n",
        "\n",
        "# import train_test_split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# splitting the data into 80% train set and 20% test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
        "\n",
        "# normalizing our data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "\n",
        "# applying Linear Discriminant Analyis\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "\n",
        "lda = LDA(n_components = 19)\n",
        "X_train = lda.fit_transform(X_train, y_train)\n",
        "X_test = lda.transform(X_test)\n",
        "\n",
        "# printing factors that affect the price of a house in order of how much weight each of the factors carry \n",
        "factors = pd.DataFrame (index = X.columns.values, data = lda.coef_[0].T)\n",
        "\n",
        "# pd.options.display.float_format = '{:.8f}'.float_format\n",
        "factors.sort_values(0, ascending = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXxe5QXufg1s"
      },
      "source": [
        "##Baseline Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nSNsdmfoFoA"
      },
      "source": [
        "# necessary imports\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eo0VV5nfc8x"
      },
      "source": [
        "X = spam.drop('class', axis = 1)\n",
        "y = spam['class']    \n",
        "\n",
        "# splitting the data into 80 - 20%\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=6) \n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "clf = GaussianNB()  \n",
        "model = clf.fit(X_train, y_train) \n",
        "\n",
        "predicted = model.predict(X_test)\n",
        "# print(np.mean(predicted == y_test))\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "print('Accuracy', accuracy_score(y_test, predicted))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L17RP6hgohJY"
      },
      "source": [
        "# evaluating the model\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn import metrics\n",
        "\n",
        "confusion_test = metrics.confusion_matrix(y_test, predicted)\n",
        "pd.DataFrame(data = confusion_test, columns = ['Predicted 0', 'Predicted 1'],\n",
        "            index = ['Actual 0', 'Actual 1'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smp55t5RpwJS"
      },
      "source": [
        "Our baseline model has an accuracy of 81.5%. As we are interested in the spam emails(class 1), We therefore have 347 cases of true positives and 411 cases of true negatives. The number of false positives is 148 which is quite high while the number of false negatives is 15. \n",
        "\n",
        "Let's employ techniques that will help in improving our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysON_FWfCbm8"
      },
      "source": [
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import auc\n",
        "\n",
        "# predict probabilities\n",
        "lr_probs = model.predict_proba(Q_test)\n",
        "\n",
        "# keep probabilities for spam emails only\n",
        "lr_probs = lr_probs[:, 1]\n",
        "\n",
        "# predict class values\n",
        "# yhat = classifier.predict(D_test)\n",
        "\n",
        "lr_precision, lr_recall, _ = precision_recall_curve(s_test, lr_probs)\n",
        "lr_f1, lr_auc = f1_score(s_test, predicted), auc(lr_recall, lr_precision)\n",
        "\n",
        "# summarize scores\n",
        "print('Gaussian: f1=%.3f auc=%.3f' % (lr_f1, lr_auc))\n",
        "\n",
        "# plot the precision-recall curves\n",
        "no_skill = len(s_test[s_test==1]) / len(s_test)\n",
        "plt.plot([0, 1], [no_skill, no_skill], linestyle='--', label='No Skill')\n",
        "plt.plot(lr_recall, lr_precision, marker='.', label='Gaussian')\n",
        "\n",
        "# axis labels\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "# show the legend\n",
        "plt.legend()\n",
        "# show the plot\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jn0fanGLEuxE"
      },
      "source": [
        "##Pre-processing - Improving model Performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwKSbXyebPax"
      },
      "source": [
        "###Multicollinearirity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFg-OMbSFjUP"
      },
      "source": [
        "# identify highly correlated features \n",
        "# create correlation matrix\n",
        "\n",
        "corr_matrix = spam.corr().abs()\n",
        "corr_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_kKUNsOGLoq"
      },
      "source": [
        "# select upper triangle of correlation matrix\n",
        "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
        "upper"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmuMt0ONHzbc"
      },
      "source": [
        "# find index of feature columns with correlation greater than 0.95\n",
        "\n",
        "to_drop = [column for column in upper.columns if any (upper[column] > 0.95)]\n",
        "to_drop"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_ljuCD2Z2IK"
      },
      "source": [
        "We got one column {word_freq_415}that a high correlation that is greater than 0.95 which we will drop in an attempt to improve model performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSd-nY7QLJoK"
      },
      "source": [
        "# drop highly correlated features\n",
        "\n",
        "spam = spam.drop(spam[to_drop], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dJHoQl7WOCZ"
      },
      "source": [
        "# calculating VIF scores to verify we do Not have any other columns that are highly correlated\n",
        "\n",
        "pd.DataFrame(np.linalg.inv(corr_matrix.values), index = corr_matrix.index, columns = corr_matrix.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewWMijlQaq9t"
      },
      "source": [
        "From the above, there is no column that has VIF score greater than 5 hence we can conclude our data does not exhibit multicollinearity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yUR4F8Tc23Y"
      },
      "source": [
        "# verifying the new shape of the datafarame\n",
        "spam.shape\n",
        "\n",
        "# verifies we dropped one column"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-s5YmC77bWVq"
      },
      "source": [
        "###Dealing with Imbalanced classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVKqSSCOfDbm"
      },
      "source": [
        "As we have imbalanced datasets i.e we have more observations of emails that are not spam as compared to spam emails. Hence, we will upsample the spam emails so we can obtain a balanced number of both spam and non-spam classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GZZ3nvTcxOK"
      },
      "source": [
        "# creating dependent and independent sets\n",
        "\n",
        "M = spam.drop('class', axis = 1)\n",
        "n = spam['class']  \n",
        "\n",
        "# normalizing our data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "M_train = sc.fit_transform(M_train)\n",
        "n_test = sc.transform(M_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FceW5WYYv0Im"
      },
      "source": [
        "# Split into train (2/3) and test (1/3) sets\n",
        "test_size = 0.33\n",
        "seed = 7\n",
        "M_train, M_test, n_train, n_test = train_test_split(M, n, test_size=test_size, random_state=seed)\n",
        "\n",
        "# Put X and y training data back together again\n",
        "Mn_train = pd.concat([M_train, n_train], axis=1)\n",
        "\n",
        "# Split into spam and non - spam\n",
        "Mn_train_0 = Mn_train[Mn_train['class']==0]\n",
        "Mn_train_1 = Mn_train[Mn_train['class']==1]\n",
        "\n",
        "# counting the two classes\n",
        "print( 'Non spam class: ', Mn_train_0.shape[0] )\n",
        "print( 'Spam class: ', Mn_train_1.shape[0] )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ptppfqCukrx"
      },
      "source": [
        "# Resampling\n",
        "from sklearn.utils import resample\n",
        "\n",
        "# Undersampling non - spam emails (as we want them to be less as it is the majority class)\n",
        "Mn_train_0_undersampled = resample(Mn_train_0, replace=True, n_samples=Mn_train_1.shape[0])\n",
        "print( Mn_train_0_undersampled.shape)\n",
        "\n",
        "# Oversample spam emails (as it is the minority class)\n",
        "Mn_train_1_oversampled = resample(Mn_train_1, replace=True, n_samples=Mn_train_0.shape[0])\n",
        "print( Mn_train_1_oversampled.shape )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nokMqdKyuukj"
      },
      "source": [
        "# We can either go with the oversampled spam, or undersampled non spam\n",
        "# Let's go with oversampling\n",
        "combined = pd.concat([Mn_train_1_oversampled, Mn_train_0])\n",
        "\n",
        "# Show that we now have balanced classes\n",
        "combined['class'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKak17pQCbIh"
      },
      "source": [
        "##Gaussian Naive Bayes Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wj_9bFsUKdG"
      },
      "source": [
        "The Naive Bayes Classifier is an algorithm for classification based on the Bayes Theorem and takes into account the assumption that the effect of a particular feature in a class is independent of other features hence why it is referred to as Naive.\n",
        "The Gaussian Naive Bayes classifier assumes that the features are normally distributed.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Am4dooefu0Cz"
      },
      "source": [
        "#\n",
        "Q = combined.drop('class', axis = 1)\n",
        "s = combined['class']   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hh1fwKkL_biA"
      },
      "source": [
        "# splitting the data into 80 - 20%\n",
        "\n",
        "Q_train, Q_test, s_train, s_test = train_test_split(Q, s, test_size=0.2, random_state=6) \n",
        "\n",
        "# normalizing our data\n",
        "# from sklearn.preprocessing import StandardScaler\n",
        "# sc = StandardScaler()\n",
        "# X_train = sc.fit_transform(X_train)\n",
        "# X_test = sc.transform(X_test)\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "clf = GaussianNB()  \n",
        "model = clf.fit(Q_train, s_train) \n",
        "\n",
        "predicted = model.predict(Q_test)\n",
        "print(np.mean(predicted == s_test))\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn import metrics\n",
        "print(classification_report(s_test, predicted))\n",
        "confusion_test = metrics.confusion_matrix(s_test, model.predict(Q_test))\n",
        "pd.DataFrame(data = confusion_test, columns = ['Predicted 0', 'Predicted 1'],\n",
        "            index = ['Actual 0', 'Actual 1'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ErOrRWCA96N"
      },
      "source": [
        "The Gaussian Naive Bayes Model has attained an accuracy score of ~85%. \n",
        "Let's break down our output:\n",
        "\n",
        "*   True Positives: 350\n",
        "*   True Negatives: 291\n",
        "*   False Positives: 100\n",
        "*   False Negatives: 16\n",
        "*   Accuracy:  0.846 our model is approximately 85% accurate\n",
        "*   Precision: 0.78 for the spam emails\n",
        "*   Recall(Sensitivity): 0.96 for the spam emails\n",
        "*   f1 score: 0.86\n",
        "\n",
        "We can consider our model a better fot than the baseline model and it is generally a good model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CufFol3BEWsH"
      },
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# generate a no skill prediction (majority class)\n",
        "ns_probs = [0 for _ in range(len(s_test))]\n",
        "\n",
        "# predict probabilities\n",
        "lr_probs = model.predict_proba(Q_test)\n",
        "\n",
        "# keep probabilities for the positive outcome only\n",
        "lr_probs = lr_probs[:, 1]\n",
        "\n",
        "# calculate scores\n",
        "ns_auc = roc_auc_score(s_test, ns_probs)\n",
        "lr_auc = roc_auc_score(s_test, lr_probs)\n",
        "\n",
        "# summarize scores\n",
        "print('No Skill: ROC AUC=%.3f' % (ns_auc))\n",
        "print('Gaussian: ROC AUC=%.3f' % (lr_auc))\n",
        "\n",
        "# calculate roc curves\n",
        "ns_fpr, ns_tpr, _ = roc_curve(s_test, ns_probs)\n",
        "lr_fpr, lr_tpr, _ = roc_curve(s_test, lr_probs)\n",
        "\n",
        "# plot the roc curve for the model\n",
        "plt.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\n",
        "plt.plot(lr_fpr, lr_tpr, marker='.', label='Gaussian')\n",
        "\n",
        "# axis labels\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "# show the legend\n",
        "plt.legend()\n",
        "# show the plot\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulXhIIcIHbYI"
      },
      "source": [
        "As we are dealing with balanced classes, we will use the ROC curve (False positive Rate against True positive Rate) to show the trade-off between sensitivity (or TPR) and specificity (1 – FPR). Our curve is close to the top left corner and has a high value of the area under the curve, an indication that our model is skillful."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2WK-T_sPS_G"
      },
      "source": [
        "R = combined.drop('class', axis = 1)\n",
        "u = combined['class']  \n",
        "\n",
        "# splitting the data into 70 - 30%\n",
        "R_train, R_test, u_train, u_test = train_test_split(R, u, test_size=0.3, random_state=6) \n",
        "\n",
        "# normalizing our data\n",
        "# from sklearn.preprocessing import StandardScaler\n",
        "# sc = StandardScaler()\n",
        "# X_train = sc.fit_transform(X_train)\n",
        "# X_test = sc.transform(X_test)\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "clf = GaussianNB()  \n",
        "model = clf.fit(R_train, u_train) \n",
        "\n",
        "predicted = model.predict(R_test)\n",
        "print(np.mean(predicted == u_test))\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn import metrics\n",
        "print(classification_report(u_test, predicted))\n",
        "confusion_test = metrics.confusion_matrix(u_test, predicted)\n",
        "pd.DataFrame(data = confusion_test, columns = ['Predicted 0', 'Predicted 1'],\n",
        "            index = ['Actual 0', 'Actual 1'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LiMxLjOIPSBV"
      },
      "source": [
        "The accuracy score has increased slightly to approximately 86%. Breaking down our outputs:\n",
        "\n",
        "True Positives: 525\n",
        "True Negatives: 448\n",
        "False Positives: 139\n",
        "False Negatives: 24\n",
        "\n",
        "The precision and recall have remained the same but the f1 score for the spam emails has increased slightly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecJlc8KrRr2V"
      },
      "source": [
        "O = combined.drop('class', axis = 1)\n",
        "p = combined['class']  \n",
        "\n",
        "# splitting the data into 60 - 40%\n",
        "O_train, O_test, p_train, p_test = train_test_split(O, p, test_size=0.4, random_state=6) \n",
        "\n",
        "# normalizing our data\n",
        "# from sklearn.preprocessing import StandardScaler\n",
        "# sc = StandardScaler()\n",
        "# X_train = sc.fit_transform(X_train)\n",
        "# X_test = sc.transform(X_test)\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "clf = GaussianNB()  \n",
        "model = clf.fit(O_train, p_train) \n",
        "\n",
        "predicted = model.predict(O_test)\n",
        "print(np.mean(predicted == p_test))\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn import metrics\n",
        "print(classification_report(p_test, predicted))\n",
        "confusion_test = metrics.confusion_matrix(p_test, predicted)\n",
        "pd.DataFrame(data = confusion_test, columns = ['Predicted 0', 'Predicted 1'],\n",
        "            index = ['Actual 0', 'Actual 1'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gn2n6O_BSI4a"
      },
      "source": [
        "This accuracy of this model has reduced slightly in comparison to prior models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hcT4MfSSWLk"
      },
      "source": [
        "##Challenging the Solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OS3vFLoSh0g"
      },
      "source": [
        "The models we have built have an accuracy of approximately 85%. And f1 score of about 0.86 which is good enough. This was obtained after employing several model performance techniques such as resampling the classes to obtain equal number of classes and dropping highly multilinear features. Hence, it would be difficult to beat this particular model. We will therefore build SVM model. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKE30UppVn06"
      },
      "source": [
        "###SVM Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9PF6M0ySaeT"
      },
      "source": [
        "R = combined.drop('class', axis = 1)\n",
        "u = combined['class']  \n",
        "\n",
        "# splitting the data into 70 - 30%\n",
        "R_train, R_test, u_train, u_test = train_test_split(R, u, test_size=0.3, random_state=6) \n",
        "\n",
        "# Building the model \n",
        "from sklearn.svm import SVC,LinearSVC\n",
        "rbfclassifier = SVC(kernel='rbf', gamma=0.01, C=2.0)\n",
        "\n",
        "# Training the model using the training set\n",
        "rbfclassifier.fit(R_train, u_train)\n",
        "\n",
        "# Predict the response for the test set\n",
        "u_pred = rbfclassifier.predict(R_test)\n",
        "\n",
        "# assessing the model\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn import metrics\n",
        "print(classification_report(u_test, u_pred))\n",
        "confusion_test = metrics.confusion_matrix(u_test, u_pred)\n",
        "pd.DataFrame(data = confusion_test, columns = ['Predicted 0', 'Predicted 1'],\n",
        "            index = ['Actual 0', 'Actual 1'])\n",
        "model_accuracy = accuracy_score(u_test,u_pred)\n",
        "print(model_accuracy)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FshmQJCLYaus"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "C_range = np.logspace(-2, 10, 13)\n",
        "gamma_range = np.logspace(-9, 3, 13)\n",
        "param_grid = dict(gamma=gamma_range, C=C_range)\n",
        "# cv = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
        "grid = GridSearchCV(SVC(kernel =\"rbf\"), param_grid=param_grid)\n",
        "grid.fit(R_train, u_train)\n",
        "\n",
        "print(\"The best parameters are %s with a score of %0.2f\"\n",
        "      % (grid.best_params_, grid.best_score_))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7AVB1PQF6FFu"
      },
      "source": [
        "The SVM model has given an accuracy score that is slightly higher than the Naive Bayes models hence this could be a bit difficult to beat. \n",
        "\n",
        "It is important to note that the Naive Bayes was a faster model as compared to SVM."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PGU7MdjC-6_"
      },
      "source": [
        "##Follow-up questions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjzGUrl-pRBQ"
      },
      "source": [
        "The Gaussian Naive Bayes Classifier is a good fit for our data, however, we did not attain our metric of success of obtaining an accuray score of at least 90%. Could this have been attributed to the fact that we were trying to classify text features hence use Multinomial Naive Bayes instead which is better at text classification?"
      ]
    }
  ]
}